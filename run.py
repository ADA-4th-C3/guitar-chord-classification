import os
import streamlit as st
import numpy as np
import sounddevice as sd
import pandas as pd
import librosa
import librosa.display
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from generate import extract_chroma
import io

MODEL_PATH = 'model/model.h5'  # í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
SAMPLE_RATE = 44100  # ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸ (generate.pyì™€ ë™ì¼í•˜ê²Œ)
DURATION = 1  # 1ì´ˆ ë‹¨ìœ„ë¡œ ìŒì› ë¶„ì„
NOISE_GATE = 0.01  # generate.pyì™€ ë™ì¼í•œ ì„ê³„ê°’
TRAINING_DATA_PATH = 'data/training'
CLASS_NAMES = sorted([
    folder for folder in os.listdir(TRAINING_DATA_PATH)
    if os.path.isdir(os.path.join(TRAINING_DATA_PATH, folder))
])


@st.cache_resource
def load_keras_model():
    """í•™ìŠµëœ Keras ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        model = load_model(MODEL_PATH)
        return model
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error(
            f"'{MODEL_PATH}' íŒŒì¼ì´ í˜„ì¬ í´ë”ì— ìˆëŠ”ì§€, TensorFlow/Kerasê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None


def preprocess_audio_chunk(audio_chunk, sr, noise_gate):
    """
    ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì–´ì˜¨ ì˜¤ë””ì˜¤ ì²­í¬(Numpy ë°°ì—´)ì—ì„œ chroma íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    generate.pyì˜ extract_chroma í•¨ìˆ˜ ë¡œì§ì„ íŒŒì¼ ì…ì¶œë ¥ ì—†ì´ ì²˜ë¦¬í•˜ë„ë¡ ë³€í˜•í–ˆìŠµë‹ˆë‹¤.
    """
    # ë…¸ì´ì¦ˆ ì œê±°
    y = audio_chunk
    if len(y) < 2048:  # ì¶©ë¶„í•œ ì‹ í˜¸ê°€ ì—†ìœ¼ë©´ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ (STFT ìµœì†Œ í¬ê¸°)
        return None

    y[np.abs(y) < noise_gate] = 0
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    return chroma


def chroma_to_model_input(chroma, target_shape=(128, 128)):
    """
    ì¶”ì¶œëœ Chroma ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•íƒœ(ì´ë¯¸ì§€ ë°°ì—´)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    generate.pyì—ì„œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•œ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì‹œê°í™” í›„,
    ì´ë¥¼ ë‹¤ì‹œ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    fig = plt.figure(figsize=(4, 4))
    # librosa.display.specshowë¥¼ ì‚¬ìš©í•˜ì—¬ generate.pyì™€ ë™ì¼í•œ ì‹œê°í™” ìƒì„±
    librosa.display.specshow(chroma, y_axis='chroma',
                             x_axis='time', cmap='coolwarm')
    plt.axis('off')

    # ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ëŒ€ì‹  ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥
    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)
    plt.close(fig)
    buf.seek(0)

    # ë©”ëª¨ë¦¬ ë²„í¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ëª¨ë¸ ì…ë ¥ì— ë§ê²Œ ì „ì²˜ë¦¬
    img = image.load_img(buf, target_size=target_shape, color_mode="rgb")
    img_array = image.img_to_array(img)
    img_array /= 255.0  # ìŠ¤ì¼€ì¼ë§ (í•™ìŠµ ë•Œì™€ ë™ì¼í•˜ê²Œ)
    img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

    return img_array


# --- Streamlit UI ---
st.set_page_config(layout="wide")
st.title("ğŸ¸ ì‹¤ì‹œê°„ ê¸°íƒ€ ì½”ë“œ ë¶„ë¥˜")
st.write(f"{DURATION}ì´ˆ ë‹¨ìœ„ë¡œ ë§ˆì´í¬ ì…ë ¥ì„ ë°›ì•„ ì½”ë“œë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ëª¨ë¸ ë¡œë“œ
model = load_keras_model()

if model:
    # ë…¹ìŒ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•´ session_state ì‚¬ìš©
    if 'is_recording' not in st.session_state:
        st.session_state.is_recording = False

    col1, col2 = st.columns([1, 2])

    with col1:
        start_button = st.button("â–¶ï¸ ì˜ˆì¸¡ ì‹œì‘", type="primary")
        stop_button = st.button("â¹ï¸ ì˜ˆì¸¡ ì¤‘ì§€")

    if start_button:
        st.session_state.is_recording = True
    if stop_button:
        st.session_state.is_recording = False

    with col2:
        st.info("ì˜ˆì¸¡ì´ ì‹œì‘ë˜ë©´ ì•„ë˜ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    # ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•œ placeholder
    placeholder = st.empty()

    if st.session_state.is_recording:
        st.toast("ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤...", icon="ğŸ¤")

    # ì‹¤ì‹œê°„ ì˜ˆì¸¡ ë£¨í”„
    while st.session_state.is_recording:
        try:
            # 1. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë…¹ìŒ
            audio_chunk = sd.rec(int(DURATION * SAMPLE_RATE),
                                 samplerate=SAMPLE_RATE, channels=1, dtype='float32')
            sd.wait()  # ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            audio_chunk = audio_chunk.flatten()

            # 2. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (generate.py ë¡œì§ í™œìš©)
            chroma = preprocess_audio_chunk(
                audio_chunk, sr=SAMPLE_RATE, noise_gate=NOISE_GATE)

            if chroma is not None:
                # 3. ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
                # ëª¨ë¸ì´ í•™ìŠµí•œ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ target_shapeì— ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ: (128, 128)
                model_input = chroma_to_model_input(
                    chroma, target_shape=(128, 128))

                # 4. ì½”ë“œ ì˜ˆì¸¡
                prediction = model.predict(model_input)[0]
                predicted_index = np.argmax(prediction)
                predicted_label = CLASS_NAMES[predicted_index]
                confidence = prediction[predicted_index]

                # 5. ê²°ê³¼ ì‹œê°í™”
                with placeholder.container():
                    st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼")
                    col_res1, col_res2 = st.columns(2)
                    with col_res1:
                        st.metric(label="ì˜ˆì¸¡ëœ ì½”ë“œ", value=f"{predicted_label}",
                                  help=f"ì‹ ë¢°ë„: {confidence:.2%}")

                        st.write("ğŸ“ˆ **ì½”ë“œë³„ ì‹ ë¢°ë„**")
                        # ì‹ ë¢°ë„ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë§Œë“¤ì–´ st.bar_chartì— ì „ë‹¬
                        confidence_df = pd.DataFrame({
                            'Code': CLASS_NAMES,
                            'Confidence': prediction
                        }).set_index('Code')
                        st.bar_chart(confidence_df)

                    with col_res2:
                        st.write("ğŸµ **ì…ë ¥ëœ ì†Œë¦¬ì˜ Chromagram**")
                        fig, ax = plt.subplots(figsize=(5, 4))
                        librosa.display.specshow(
                            chroma, y_axis='chroma', x_axis='time', ax=ax, cmap='coolwarm')
                        ax.set_title("Real-time Chroma")
                        st.pyplot(fig)
            else:
                with placeholder.container():
                    st.warning("ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ì•„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” í¬ê²Œ ì—°ì£¼í•´ì£¼ì„¸ìš”.", icon="ğŸ”‡")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.session_state.is_recording = False
            break

    if not st.session_state.is_recording:
        st.toast("ì˜ˆì¸¡ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
